#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIé€Ÿåº¦æµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰å·²é…ç½®çš„APIå“åº”é€Ÿåº¦
"""

import time
import requests
import statistics
from datetime import datetime
import json
import sys
import io

# ä¿®å¤Windows GBKç¼–ç é—®é¢˜
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# APIé…ç½®æ¸…å•
API_CONFIGS = {
    "è‹±ä¼Ÿè¾¾1 (ä¸»è´¦æˆ·)": {
        "provider": "nvidia",
        "url": "https://integrate.api.nvidia.com/v1/chat/completions",
        "api_key": "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",
        "model": "z-ai/glm4.7",
        "note": "æ€è€ƒæ¨¡å¼ enabled"
    },
    "è‹±ä¼Ÿè¾¾2 (å¤‡ç”¨)": {
        "provider": "nvidia",
        "url": "https://integrate.api.nvidia.com/v1/chat/completions",
        "api_key": "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",
        "model": "z-ai/glm4.7",
        "note": "æ€è€ƒæ¨¡å¼ enabled"
    },
    "æ··å…ƒ (è…¾è®¯)": {
        "provider": "hunyuan",
        "url": "https://api.hunyuan.cloud.tencent.com/v1/chat/completions",
        "api_key": "sk-7xGaNZwkW0CLZNeT8kZrJv2hiHpU47wzS8XVhOagKKjLyb2i",
        "model": "hunyuan-lite",
        "note": "256kä¸Šä¸‹æ–‡ï¼Œæ— RPMé™åˆ¶"
    },
    "SiliconFlow (embeddings)": {
        "provider": "siliconflow",
        "url": "https://api.siliconflow.cn/v1/embeddings",
        "api_key": "sk-kvqpfofevcxloxexrrjovsjzpnwsvhpwrbxkwjydwbjyufjf",
        "model": "BAAI/bge-large-zh-v1.5",
        "note": "ä»…ç”¨äºembeddings"
    }
}

# æµ‹è¯•æç¤ºè¯
TEST_PROMPT_SIMPLE = "ä½ å¥½"
TEST_PROMPT_COMPLEX = "è¯·å†™ä¸€ä¸ª100å­—çš„å…³äºäººå·¥æ™ºèƒ½å‘å±•çš„å°æ•…äº‹"
TEST_PROMPT_EMBEDDING = "äººå·¥æ™ºèƒ½å‘å±•çš„é‡è¦æ„ä¹‰"


class APITester:
    def __init__(self):
        self.results = {}

    def test_chat_completion(self, name, config, prompt, test_rounds=3):
        """æµ‹è¯•èŠå¤©API"""
        print(f"\n{'='*70}")
        print(f"æµ‹è¯•: {name}")
        print(f"é…ç½®: {config}")
        print(f"æç¤ºè¯: {prompt}")
        print(f"{'='*70}")

        headers = {
            "Authorization": f"Bearer {config['api_key']}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": config['model'],
            "messages": [{"role": "user", "content": prompt}],
            "stream": False,
            "temperature": 0.7,
            "max_tokens": 1000
        }

        # è‹±ä¼Ÿè¾¾ç‰¹æœ‰å‚æ•°
        if config['provider'] == 'nvidia':
            payload['extra_body'] = {
                "chat_template_kwargs": {
                    "enable_thinking": True,
                    "clear_thinking": False
                }
            }

        latencies = []
        responses = []
        tokens = []

        for i in range(test_rounds):
            print(f"\nç¬¬ {i+1}/{test_rounds} è½®æµ‹è¯•...")

            try:
                start_time = time.time()

                response = requests.post(
                    config['url'],
                    headers=headers,
                    json=payload,
                    timeout=120
                )

                end_time = time.time()
                latency = end_time - start_time

                response.raise_for_status()
                result = response.json()

                # æå–ä¿¡æ¯
                try:
                    content = result['choices'][0]['message']['content']
                except (KeyError, IndexError, TypeError) as e:
                    print(f"  âœ— è§£æå“åº”å¤±è´¥: {e}")
                    print(f"  âœ— å“åº”ç»“æ„: {result}")
                    return None

                total_tokens = result.get('usage', {}).get('total_tokens', 0)

                # æ£€æŸ¥contentæ˜¯å¦ä¸ºNoneæˆ–ç©º
                if content is None or content == "":
                    print(f"  âœ— å“åº”å†…å®¹ä¸ºç©º")
                    return None

                latencies.append(latency)
                responses.append(content)
                tokens.append(total_tokens)

                print(f"  âœ“ å»¶è¿Ÿ: {latency:.2f}ç§’")
                print(f"  âœ“ Tokens: {total_tokens}")
                print(f"  âœ“ å“åº”é•¿åº¦: {len(content)}å­—ç¬¦")

                # æ˜¾ç¤ºå“åº”ï¼ˆæˆªæ–­ï¼‰
                short_content = content[:100] + "..." if len(content) > 100 else content
                print(f"  âœ“ å“åº”: {short_content}")

            except requests.exceptions.RequestException as e:
                print(f"  âœ— é”™è¯¯: {e}")
                return None

        # ç»Ÿè®¡
        stats = {
            "avg_latency": statistics.mean(latencies),
            "min_latency": min(latencies),
            "max_latency": max(latencies),
            "avg_tokens": statistics.mean(tokens),
            "responses": responses,
            "all_latencies": latencies,
            "all_tokens": tokens
        }

        print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"  å¹³å‡å»¶è¿Ÿ: {stats['avg_latency']:.2f}ç§’")
        print(f"  æœ€å°å»¶è¿Ÿ: {stats['min_latency']:.2f}ç§’")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {stats['max_latency']:.2f}ç§’")
        print(f"  å¹³å‡Tokens: {stats['avg_tokens']:.0f}")

        return stats

    def test_embeddings(self, name, config, prompt, test_rounds=3):
        """æµ‹è¯•Embedding API"""
        print(f"\n{'='*70}")
        print(f"æµ‹è¯•: {name} (Embeddings)")
        print(f"é…ç½®: {config}")
        print(f"æç¤ºè¯: {prompt}")
        print(f"{'='*70}")

        headers = {
            "Authorization": f"Bearer {config['api_key']}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": config['model'],
            "input": prompt,
            "encoding_format": "float"
        }

        latencies = []
        dimensions = []

        for i in range(test_rounds):
            print(f"\nç¬¬ {i+1}/{test_rounds} è½®æµ‹è¯•...")

            try:
                start_time = time.time()

                response = requests.post(
                    config['url'],
                    headers=headers,
                    json=payload,
                    timeout=60
                )

                end_time = time.time()
                latency = end_time - start_time

                response.raise_for_status()
                result = response.json()

                dims = len(result['data'][0]['embedding'])

                latencies.append(latency)
                dimensions.append(dims)

                print(f"  âœ“ å»¶è¿Ÿ: {latency:.2f}ç§’")
                print(f"  âœ“ ç»´åº¦: {dims}")

            except requests.exceptions.RequestException as e:
                print(f"  âœ— é”™è¯¯: {e}")
                return None

        # ç»Ÿè®¡
        stats = {
            "avg_latency": statistics.mean(latencies),
            "min_latency": min(latencies),
            "max_latency": max(latencies),
            "dimensions": dimensions[0] if dimensions else 0,
            "all_latencies": latencies
        }

        print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"  å¹³å‡å»¶è¿Ÿ: {stats['avg_latency']:.2f}ç§’")
        print(f"  æœ€å°å»¶è¿Ÿ: {stats['min_latency']:.2f}ç§’")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {stats['max_latency']:.2f}ç§’")
        print(f"  å‘é‡ç»´åº¦: {stats['dimensions']}")

        return stats

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print(f"\n{'='*70}")
        print(f"APIé€Ÿåº¦æµ‹è¯•å¼€å§‹")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*70}")

        # æµ‹è¯•ç®€å•æç¤ºè¯
        print(f"\n\n{'#'*70}")
        print(f"# æµ‹è¯•1: ç®€å•æç¤ºè¯")
        print(f"{'#'*70}\n")

        for name, config in API_CONFIGS.items():
            if config['provider'] != 'siliconflow':
                result = self.test_chat_completion(
                    name, config, TEST_PROMPT_SIMPLE, test_rounds=3
                )
                if result:
                    self.results[f"{name}_simple"] = result

        # æµ‹è¯•å¤æ‚æç¤ºè¯
        print(f"\n\n{'#'*70}")
        print(f"# æµ‹è¯•2: å¤æ‚æç¤ºè¯")
        print(f"{'#'*70}\n")

        for name, config in API_CONFIGS.items():
            if config['provider'] != 'siliconflow':
                result = self.test_chat_completion(
                    name, config, TEST_PROMPT_COMPLEX, test_rounds=3
                )
                if result:
                    self.results[f"{name}_complex"] = result

        # æµ‹è¯•Embeddings
        print(f"\n\n{'#'*70}")
        print(f"# æµ‹è¯•3: Embeddings")
        print(f"{'#'*70}\n")

        for name, config in API_CONFIGS.items():
            if config['provider'] == 'siliconflow':
                result = self.test_embeddings(
                    name, config, TEST_PROMPT_EMBEDDING, test_rounds=3
                )
                if result:
                    self.results[f"{name}_embeddings"] = result

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_report()

    def generate_report(self):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        print(f"\n\n{'#'*70}")
        print(f"# ğŸ“Š APIé€Ÿåº¦æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        print(f"{'#'*70}\n")

        # ç®€å•æç¤ºè¯å¯¹æ¯”
        print(f"{'='*70}")
        print(f"æµ‹è¯•1: ç®€å•æç¤ºè¯ ('ä½ å¥½')")
        print(f"{'='*70}\n")
        self.print_comparison_table("simple")

        # å¤æ‚æç¤ºè¯å¯¹æ¯”
        print(f"\n\n{'='*70}")
        print(f"æµ‹è¯•2: å¤æ‚æç¤ºè¯ (100å­—æ•…äº‹)")
        print(f"{'='*70}\n")
        self.print_comparison_table("complex")

        # Embeddingsæµ‹è¯•
        print(f"\n\n{'='*70}")
        print(f"æµ‹è¯•3: Embeddings")
        print(f"{'='*70}\n")

        embeddings_key = "SiliconFlow (embeddings)_embeddings"
        if embeddings_key in self.results:
            result = self.results[embeddings_key]
            print(f"æä¾›å•†: SiliconFlow")
            print(f"æ¨¡å‹: BAAI/bge-large-zh-v1.5")
            print(f"å¹³å‡å»¶è¿Ÿ: {result['avg_latency']:.2f}ç§’")
            print(f"æœ€å°å»¶è¿Ÿ: {result['min_latency']:.2f}ç§’")
            print(f"æœ€å¤§å»¶è¿Ÿ: {result['max_latency']:.2f}ç§’")
            print(f"å‘é‡ç»´åº¦: {result['dimensions']}")

        # æ€»ä½“æ’å
        print(f"\n\n{'#'*70}")
        print(f"# ğŸ† é€Ÿåº¦æ’å")
        print(f"{'#'*70}\n")

        self.print_ranking("simple", "ç®€å•æç¤ºè¯")
        self.print_ranking("complex", "å¤æ‚æç¤ºè¯")

        # ä¿å­˜JSONæŠ¥å‘Š
        self.save_json_report()

    def print_comparison_table(self, test_type):
        """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
        print(f"{'æä¾›å•†':<20} {'æ¨¡å‹':<15} {'å¹³å‡å»¶è¿Ÿ(ç§’)':<12} {'æœ€å°å»¶è¿Ÿ(ç§’)':<12} {'æœ€å¤§å»¶è¿Ÿ(ç§’)':<12}")
        print(f"{'-'*70}")

        for key, result in self.results.items():
            if key.endswith(f"_{test_type}"):
                name = key.replace(f"_{test_type}", "")
                model = "z-ai/glm4.7" if "è‹±ä¼Ÿè¾¾" in name else "hunyuan-lite"
                print(f"{name:<20} {model:<15} "
                      f"{result['avg_latency']:<12.2f} "
                      f"{result['min_latency']:<12.2f} "
                      f"{result['max_latency']:<12.2f}")

    def print_ranking(self, test_type, label):
        """æ‰“å°æ’å"""
        print(f"\n{label}æ’å:")
        print(f"{'æ’å':<6} {'æä¾›å•†':<20} {'å¹³å‡å»¶è¿Ÿ(ç§’)':<12} {'å¤‡æ³¨':<30}")
        print(f"{'-'*68}")

        # æå–ç»“æœå¹¶æ’åº
        items = [(key, result) for key, result in self.results.items()
                 if key.endswith(f"_{test_type}")]
        items.sort(key=lambda x: x[1]['avg_latency'])

        for rank, (key, result) in enumerate(items, 1):
            name = key.replace(f"_{test_type}", "")
            note = ""
            if "è‹±ä¼Ÿè¾¾1" in name:
                note = "æ€è€ƒæ¨¡å¼"
            elif "è‹±ä¼Ÿè¾¾2" in name:
                note = "æ€è€ƒæ¨¡å¼"
            elif "æ··å…ƒ" in name:
                note = "æœ€å¿«"

            medal = ""
            if rank == 1:
                medal = "ğŸ¥‡"
            elif rank == 2:
                medal = "ğŸ¥ˆ"
            elif rank == 3:
                medal = "ğŸ¥‰"

            print(f"{rank:<6} {medal} {name:<20} {result['avg_latency']:<12.2f} {note:<30}")

    def save_json_report(self):
        """ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š"""
        report = {
            "test_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "api_configs": API_CONFIGS,
            "test_results": self.results
        }

        filename = f"api_speed_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\n\nâœ… JSONæŠ¥å‘Šå·²ä¿å­˜: {filename}")


if __name__ == "__main__":
    tester = APITester()
    tester.run_all_tests()
