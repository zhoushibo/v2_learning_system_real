"""
å­¦ä¹ ç¼“å­˜ç³»ç»Ÿ

é™ä½APIè°ƒç”¨é¢‘ç‡ï¼ŒèŠ‚çœæˆæœ¬ï¼Œé¿å…é™æµ
"""
import json
import hashlib
from typing import Dict, List, Optional
from datetime import datetime
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class LearningCache:
    """å­¦ä¹ ç¼“å­˜ç³»ç»Ÿ"""

    def __init__(self, cache_file: Optional[Path] = None):
        """
        åˆå§‹åŒ–ç¼“å­˜

        Args:
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        if cache_file:
            self.cache_file = cache_file
        else:
            self.cache_file = Path(__file__).parent.parent / "data" / "learning_cache.json"

        self.cache: Dict[str, dict] = {}
        self._load_cache()

    def _get_cache_key(self, topic: str, perspective: str, style: str = "deep_analysis") -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®

        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            perspective: å­¦ä¹ è§†è§’
            style: å­¦ä¹ é£æ ¼

        Returns:
            ç¼“å­˜é”®ï¼ˆMD5å“ˆå¸Œï¼‰
        """
        key_str = f"{topic}:{perspective}:{style}"
        return hashlib.md5(key_str.encode()).hexdigest()

    def get(self, topic: str, perspective: str, style: str = "deep_analysis") -> Optional[dict]:
        """
        è·å–ç¼“å­˜ç»“æœ

        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            perspective: å­¦ä¹ è§†è§’
            style: å­¦ä¹ é£æ ¼

        Returns:
            ç¼“å­˜ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        key = self._get_cache_key(topic, perspective, style)

        if key in self.cache:
            result = self.cache[key]
            logger.info(f"âœ… ç¼“å­˜å‘½ä¸­: {topic} ({perspective})")
            return result

        logger.info(f"âŒ ç¼“å­˜æœªå‘½ä¸­: {topic} ({perspective})")
        return None

    def set(self, topic: str, perspective: str, result: dict, style: str = "deep_analysis"):
        """
        è®¾ç½®ç¼“å­˜

        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            perspective: å­¦ä¹ è§†è§’
            result: å­¦ä¹ ç»“æœ
            style: å­¦ä¹ é£æ ¼
        """
        key = self._get_cache_key(topic, perspective, style)

        self.cache[key] = {
            "topic": topic,
            "perspective": perspective,
            "style": style,
            "result": result,
            "cached_at": datetime.now().isoformat()
        }

        logger.info(f"ğŸ’¾ ç¼“å­˜ä¿å­˜: {topic} ({perspective})")
        self._save_cache()

    def _load_cache(self):
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        if self.cache_file and self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.cache = data.get("cache", {})
                logger.info(f"âœ… åŠ è½½ç¼“å­˜: {len(self.cache)} æ¡è®°å½•")
            except Exception as e:
                logger.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
                self.cache = {}

    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
        if self.cache_file:
            try:
                self.cache_file.parent.mkdir(parents=True, exist_ok=True)
                with open(self.cache_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        "cache": self.cache,
                        "last_updated": datetime.now().isoformat()
                    }, f, ensure_ascii=False, indent=2)
            except Exception as e:
                logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            "total_entries": len(self.cache),
            "cache_file": str(self.cache_file) if self.cache_file else None
        }

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache = {}
        self._save_cache()
        logger.info("ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç©º")
