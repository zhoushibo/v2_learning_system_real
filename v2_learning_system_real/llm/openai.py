"""
OpenAIProvider - OpenAI APIæä¾›è€…

ä½¿ç”¨OpenAI GPTæ¨¡å‹è¿›è¡Œå­¦ä¹ 
æ”¯æŒè‡ªå®šä¹‰base_urlï¼ˆå¦‚NVIDIA APIï¼‰

ç‰¹åˆ«æ³¨æ„ï¼š
- GLM4.7ç­‰æ¨¡å‹ä½¿ç”¨reasoning_contentè€Œécontentå­—æ®µ
- GLM4.7éœ€è¦max_tokens=4000ä»¥ä¸Šæ‰èƒ½è¾“å‡ºå®Œæ•´JSON
"""
import logging
import json
import re
from typing import Dict, List, Optional
from openai import AsyncOpenAI, Timeout
import asyncio


from .base import LLMProvider, APIError, RateLimitError, AuthenticationError, InvalidResponseError

logger = logging.getLogger(__name__)


class OpenAIProvider(LLMProvider):

    # â­ API Key æ± ï¼ˆè´Ÿè½½å‡è¡¡ + è‡ªåŠ¨åˆ‡æ¢ï¼‰
    API_KEY_POOL = [
        "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",  # ä¸» Key
        "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",  # å¤‡ç”¨ Key
    ]
    """
    OpenAI APIæä¾›è€…

    æ”¯æŒçš„æ¨¡å‹ï¼š
    - gpt-3.5-turbo: å¿«é€Ÿï¼Œä¾¿å®œ
    - gpt-4: é«˜è´¨é‡
    - gpt-4-turbo: GPT-4çš„æ›´å¿«ç‰ˆæœ¬

    ä¹Ÿæ”¯æŒOpenAIå…¼å®¹çš„APIï¼š
    - NVIDIA API: https://integrate.api.nvidia.com/v1
    - å…¶ä»–å…¼å®¹OpenAIæ ¼å¼çš„API

    æ³¨æ„ï¼š
    - GLM4.7ç­‰æ¨¡å‹ä½¿ç”¨reasoning_contentè€Œécontentå­—æ®µ
    - GLM4.7éœ€è¦max_tokens=4000ä»¥ä¸Šï¼ˆmax_tokens=8000æ›´å®‰å…¨ï¼‰
    - â­ æ–°å¢ï¼šè¶…æ—¶æœºåˆ¶ï¼Œé˜²æ­¢å¡ä½
    """

    # â­ å¤šæ¨¡å‹æ± ï¼ˆè‡ªåŠ¨ fallbackï¼‰
    MODEL_POOL = [
        "qwen/qwen3.5-397b-a17b",              # ä¸»æ¨¡å‹ï¼Œ397B
        "z-ai/glm5",                           # æœ€æ–° GLM-5
        "moonshotai/kimi-k2.5",                # Kimi K2.5
        "qwen/qwen3-next-80b-a3b-instruct",    # Qwen3-Next 80B
        "z-ai/glm4.7",                         # å¤‡ç”¨ GLM-4.7
    ]
    DEFAULT_MODEL = MODEL_POOL[0]
    FALLBACK_MODEL = MODEL_POOL[1] if len(MODEL_POOL) > 1 else MODEL_POOL[0]

    # â­ æ–°å¢ï¼šè¶…æ—¶é…ç½®
    DEFAULT_TIMEOUT = 180.0  # 3åˆ†é’Ÿï¼ˆGLM4.7å¯èƒ½éœ€è¦2-3åˆ†é’Ÿï¼‰
    CONNECT_TIMEOUT = 10.0  # è¿æ¥è¶…æ—¶10ç§’

    def __init__(self, api_key: str = None, model: str = None, base_url: str = None, max_tokens: int = None, timeout: float = None):
        """
        åˆå§‹åŒ–OpenAIæä¾›è€…

        Args:
            api_key: OpenAI APIå¯†é’¥
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šgpt-4ï¼‰
            base_url: è‡ªå®šä¹‰base_urlï¼ˆå¦‚NVIDIA APIï¼‰
            max_tokens: æœ€å¤§è¾“å‡ºtokensï¼ˆGLM4.7å»ºè®®4000-8000ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤180ç§’ï¼‰
        """
        # â­ é»˜è®¤ä½¿ç”¨ NVIDIA API
        if base_url is None:
            base_url = "https://integrate.api.nvidia.com/v1"
        
        super().__init__(api_key, model or self.DEFAULT_MODEL)
        self.base_url = base_url
        
        # â­ ä¿®å¤ï¼šç¡®ä¿ api_key å§‹ç»ˆæœ‰å€¼ï¼ˆåœ¨ super() ä¹‹åï¼‰
        if api_key is None:
            api_key = self.API_KEY_POOL[0]
        
        self.api_key_index = self.API_KEY_POOL.index(api_key) if api_key in self.API_KEY_POOL else 0
        self.timeout = timeout or self.DEFAULT_TIMEOUT

        # é’ˆå¯¹GLM4.7è‡ªåŠ¨è°ƒæ•´max_tokens
        # é’ˆå¯¹ä¸åŒæ¨¡å‹è°ƒæ•´ max_tokens
        model_lower = (model or "").lower()
        if "glm" in model_lower:
            self.max_tokens = 8000 if max_tokens is None else max(max_tokens, 4000)
        elif "qwen" in model_lower:
            # Qwen3.5 æ”¯æŒ 262K ä¸Šä¸‹æ–‡ï¼Œæ¨è max_tokens=16384
            self.max_tokens = 16384 if max_tokens is None else max(max_tokens, 8000)
        else:
            self.max_tokens = max_tokens or 2000

        # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆå¸¦è¶…æ—¶ï¼‰
        # ç¡®ä¿ api_key ä¸ä¸º None
        if api_key is None:
            api_key = self.API_KEY_POOL[0]
        
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url,
            timeout=Timeout(
                connect=self.CONNECT_TIMEOUT,
                read=self.timeout,
                write=self.timeout,
                pool=self.DEFAULT_TIMEOUT
            )
        )

        if base_url:
            logger.info(f"OpenAIProviderä½¿ç”¨è‡ªå®šä¹‰base_url: {base_url}, max_tokens={self.max_tokens}, timeout={self.timeout}s")

    async def learning(
        self,
        topic: str,
        perspective: str,
        style: str = "deep_analysis"
    ) -> Dict[str, List[str]]:
        """
        ä½¿ç”¨OpenAI GPTå­¦ä¹ ä¸»é¢˜

        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            perspective: å­¦ä¹ è§†è§’
            style: å­¦ä¹ é£æ ¼

        Returns:
            å­¦ä¹ ç»“æœå­—å…¸

        Raises:
            APIError: APIè°ƒç”¨å¤±è´¥
            RateLimitError: é€Ÿç‡é™åˆ¶
            AuthenticationError: è®¤è¯å¤±è´¥
        """
        try:
            # æ„å»ºPrompt
            prompt = self._build_prompt(topic, perspective, style)

            # è°ƒç”¨OpenAI API
            api_name = self.base_url if self.base_url else "OpenAI"
            logger.info(f"è¯·æ±‚APIå­¦ä¹ : {topic} ({perspective}) [{api_name}]")

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯ä¸“å®¶ï¼Œæ“…é•¿æ·±åº¦å­¦ä¹ å’ŒçŸ¥è¯†æ€»ç»“ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=self.max_tokens
                # â­ è¶…æ—¶å·²åœ¨åˆå§‹åŒ–æ—¶è®¾ç½®
            )

            # è§£æå“åº”
            # æ³¨æ„ï¼šGLM4.7ç­‰æ¨¡å‹ä½¿ç”¨reasoning_contentè€Œécontent
            content = self._extract_content(response)

            if not content:
                logger.error(f"å“åº”æ— contentå­—æ®µ: {response}")
                raise InvalidResponseError("å“åº”æ ¼å¼é”™è¯¯ï¼šæ— contentæˆ–reasoning_contentå­—æ®µ")

            logger.debug(f"APIå“åº”å†…å®¹: {content[:200]}...")

            result = self._parse_response(content)

            # è®°å½•ä½¿ç”¨æƒ…å†µ
            logger.info(f"APIå­¦ä¹ å®Œæˆ: {topic} ({perspective})")
            logger.debug(f"ä½¿ç”¨çš„tokens: {response.usage.total_tokens}")

            return result

        except asyncio.TimeoutError as e:
            logger.error(f"APIè°ƒç”¨è¶…æ—¶ï¼ˆ{self.timeout}sï¼‰: {e}")
            raise APIError(f"APIè°ƒç”¨è¶…æ—¶: {e}")

        except AuthenticationError as e:
            logger.error(f"APIè®¤è¯å¤±è´¥: {e}")
            raise AuthenticationError(f"APIå¯†é’¥æ— æ•ˆ: {e}")

        except RateLimitError as e:
            logger.warning(f"APIé€Ÿç‡é™åˆ¶: {e}")
            raise RateLimitError(f"APIé€Ÿç‡é™åˆ¶: {e}")

        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
            raise APIError(f"APIè°ƒç”¨å¤±è´¥: {e}")

    def _extract_content(self, response) -> Optional[str]:
        """
        ä»å“åº”ä¸­æå–å†…å®¹

        æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        1. æ ‡å‡†OpenAI: response.choices[0].message.content
        2. GLM4.7: response.choices[0].message.reasoning_content

        Args:
            response: OpenAIå“åº”å¯¹è±¡

        Returns:
            å†…å®¹å­—ç¬¦ä¸²
        """
        if not response.choices or len(response.choices) == 0:
            return None

        message = response.choices[0].message

        # ä¼˜å…ˆä½¿ç”¨contentï¼ˆæ ‡å‡†OpenAIæ ¼å¼ï¼‰
        if hasattr(message, 'content') and message.content:
            return message.content

        # å¦‚æœcontentä¸ºç©ºï¼Œå°è¯•reasoning_contentï¼ˆGLM4.7æ ¼å¼ï¼‰
        if hasattr(message, 'reasoning_content') and message.reasoning_content:
            return message.reasoning_content

        # éƒ½æ²¡æœ‰ï¼Œè¿”å›None
        return None


    async def learning_with_fallback(
        self,
        topic: str,
        perspective: str,
        style: str = "deep_analysis",
        max_retries: int = 3
    ) -> dict:
        """
        å¸¦è‡ªåŠ¨ fallback çš„å­¦ä¹ æ–¹æ³•
        
        ç­–ç•¥ï¼š
        1. å°è¯•ä¸»æ¨¡å‹
        2. å¤±è´¥åˆ™åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹
        3. æœ€å¤šé‡è¯• max_retries æ¬¡
        
        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            perspective: å­¦ä¹ è§†è§’
            style: å­¦ä¹ é£æ ¼
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            å­¦ä¹ ç»“æœå­—å…¸
            
        Raises:
            APIError: æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        """
        last_error = None
        
        # éå†æ¨¡å‹æ± å’Œ API Key æ± 
        for i, model in enumerate(self.MODEL_POOL):
            current_model = self.model
            current_key_index = self.api_key_index
            
            try:
                # åˆ‡æ¢åˆ°å½“å‰æ¨¡å‹
                self.model = model
                logger.info(f"å°è¯•æ¨¡å‹ [{i+1}/{len(self.MODEL_POOL)}]: {model} [Key #{current_key_index + 1}]")
                
                # è°ƒç”¨å­¦ä¹ ï¼ˆå¸¦é‡è¯•ï¼‰
                for attempt in range(max_retries):
                    try:
                        result = await self.learning(topic, perspective, style)
                        logger.info(f"âœ… æ¨¡å‹ {model} å­¦ä¹ æˆåŠŸ")
                        return result
                    except Exception as e:
                        if attempt < max_retries - 1:
                            logger.warning(f"æ¨¡å‹ {model} ç¬¬{attempt+1}æ¬¡å¤±è´¥ï¼Œé‡è¯•...: {e}")
                            import asyncio
                            await asyncio.sleep(1 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                        else:
                            raise
                
            except Exception as e:
                last_error = e
                logger.warning(f"âŒ æ¨¡å‹ {model} [Key #{current_key_index + 1}] å¤±è´¥ï¼š{e}")
                
                # å°è¯•åˆ‡æ¢ API Key
                if self.switch_api_key():
                    logger.info(f"ğŸ”„ å·²åˆ‡æ¢åˆ°æ–° API Keyï¼Œç»§ç»­å°è¯•å½“å‰æ¨¡å‹ {model}")
                    # ç”¨æ–° Key é‡è¯•å½“å‰æ¨¡å‹
                    try:
                        self.model = model
                        for attempt in range(max_retries):
                            try:
                                result = await self.learning(topic, perspective, style)
                                logger.info(f"âœ… æ¨¡å‹ {model} [Key #{self.api_key_index + 1}] å­¦ä¹ æˆåŠŸ")
                                return result
                            except Exception as retry_error:
                                if attempt < max_retries - 1:
                                    logger.warning(f"æ¨¡å‹ {model} ç¬¬{attempt+1}æ¬¡é‡è¯•å¤±è´¥ï¼š{retry_error}")
                                    import asyncio
                                    await asyncio.sleep(1 * (attempt + 1))
                                else:
                                    raise
                    except Exception as retry_error:
                        logger.warning(f"æ¨¡å‹ {model} ç”¨æ–° Key é‡è¯•å¤±è´¥ï¼š{retry_error}")
                
                # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                continue
            finally:
                # æ¢å¤åŸæ¨¡å‹
                self.model = current_model
        
        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        error_msg = f"æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼ˆå°è¯•äº† {len(self.MODEL_POOL)} ä¸ªæ¨¡å‹ï¼‰"
        logger.error(error_msg)
        if last_error:
            error_msg += f" æœ€åé”™è¯¯ï¼š{last_error}"
        raise APIError(error_msg)


    def switch_api_key(self):
        """
        åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API Keyï¼ˆç”¨äº fallbackï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        if len(self.API_KEY_POOL) <= 1:
            return False
        
        # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª Key
        self.api_key_index = (self.api_key_index + 1) % len(self.API_KEY_POOL)
        new_key = self.API_KEY_POOL[self.api_key_index]
        
        # æ›´æ–°å®¢æˆ·ç«¯
        self.client = AsyncOpenAI(
            api_key=new_key,
            base_url=self.base_url,
            timeout=Timeout(
                connect=self.CONNECT_TIMEOUT,
                read=self.timeout,
                write=self.timeout,
                pool=self.DEFAULT_TIMEOUT
            )
        )
        
        logger.info(f"ğŸ”„ åˆ‡æ¢åˆ° API Key #{self.api_key_index + 1}")
        return True

    async def validate_key(self) -> bool:
        """
        éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ

        Returns:
            å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # å°è¯•åˆ—å‡ºæ¨¡å‹
            await self.client.models.list()
            api_name = self.base_url if self.base_url else "OpenAI"
            logger.info(f"{api_name} APIå¯†é’¥éªŒè¯æˆåŠŸ")
            return True
        except AuthenticationError:
            logger.error("APIå¯†é’¥æ— æ•ˆ")
            return False
        except Exception as e:
            logger.warning(f"APIå¯†é’¥éªŒè¯å¤±è´¥: {e}")
            return False

    def _build_prompt(self, topic: str, perspective: str, style: str) -> str:
        """
        æ„å»ºå­¦ä¹ Prompt

        Args:
            topic: å­¦ä¹ ä¸»é¢˜
            perspective: å­¦ä¹ è§†è§’
            style: å­¦ä¹ é£æ ¼

        Returns:
            Promptå­—ç¬¦ä¸²
        """
        if style == "deep_analysis":
            prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„{perspective}ã€‚

è¯·æ·±åº¦å­¦ä¹ ä»¥ä¸‹ä¸»é¢˜ï¼š{topic}

è¦æ±‚ï¼š
1. æ·±åº¦ç†è§£ï¼šä¸æ˜¯è¡¨é¢ä»‹ç»ï¼Œè€Œæ˜¯åº•å±‚åŸç†
2. å®è·µå¯¼å‘ï¼šç»“åˆå®é™…é¡¹ç›®ç»éªŒ
3. å¯æ“ä½œå»ºè®®ï¼šæä¾›ç«‹å³å¯ç”¨çš„å»ºè®®
4. æœ€æ–°ä¿¡æ¯ï¼šå…³æ³¨æœ€æ–°å‘å±•

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
  "lessons": [
    "è¯¾ç¨‹æ ‡é¢˜1 - 10-15å­—",
    "è¯¾ç¨‹æ ‡é¢˜2 - 10-15å­—",
    "..."
  ],
  "key_points": [
    "è¦ç‚¹1 - ä¸€å¥è¯æ€»ç»“",
    "è¦ç‚¹2 - ä¸€å¥è¯æ€»ç»“",
    "..."
  ],
  "recommendations": [
    "å…·ä½“å¯æ“ä½œçš„å»ºè®®1 - 20-30å­—",
    "å…·ä½“å¯æ“ä½œçš„å»ºè®®2 - 20-30å­—",
    "..."
  ]
}}

ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œä¸è¦æœ‰è¯­æ³•é”™è¯¯ã€‚
"""
        else:  # quick_overview
            prompt = f"""
è¯·å¿«é€Ÿäº†è§£{topic}ï¼ˆä»{perspective}è§†è§’ï¼‰ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
  "lessons": ["è¯¾ç¨‹1", "è¯¾ç¨‹2", "è¯¾ç¨‹3"],
  "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
  "recommendations": ["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]
}}
"""

        return prompt

    def _parse_response(self, content: str) -> Dict[str, List[str]]:
        """
        è§£æLLMå“åº”

        Args:
            content: LLMå“åº”å†…å®¹

        Returns:
            å­¦ä¹ ç»“æœå­—å…¸

        Raises:
            InvalidResponseError: å“åº”æ ¼å¼é”™è¯¯
        """
        try:
            # å°è¯•æå–JSONï¼ˆå¯èƒ½åŒ…å«```json ```ï¼‰
            json_str = self._extract_json(content)

            # è§£æJSON
            result = json.loads(json_str)

            # éªŒè¯æ ¼å¼
            required_keys = ["lessons", "key_points", "recommendations"]
            for key in required_keys:
                if key not in result:
                    raise InvalidResponseError(f"å“åº”ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")

                if not isinstance(result[key], list):
                    raise InvalidResponseError(f"å­—æ®µ{key}ä¸æ˜¯åˆ—è¡¨ç±»å‹")

            # éªŒè¯æ¯ä¸ªå­—æ®µéƒ½æœ‰å†…å®¹
            for key in required_keys:
                if len(result[key]) == 0:
                    logger.warning(f"å­—æ®µ{key}ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    result[key] = self._get_default_content(key)

            return result

        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            logger.debug(f"åŸå§‹å†…å®¹: {content}")

            # å°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
            return self._extract_with_regex(content)

        except Exception as e:
            logger.error(f"å“åº”è§£æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return self._get_default_result()

    def _extract_json(self, content: str) -> str:
        """
        ä»å†…å®¹ä¸­æå–JSONå­—ç¬¦ä¸²

        Args:
            content: å†…å®¹å­—ç¬¦ä¸²

        Returns:
            JSONå­—ç¬¦ä¸²
        """
        # å°è¯•ç§»é™¤```json ```æ ‡è®°
        patterns = [
            r'```json\s*([\s\S]*?)\s*```',
            r'```\s*([\s\S]*?)\s*```',
            r'\{[\s\S]*\}'
        ]

        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1).strip()

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œç›´æ¥è¿”å›åŸå†…å®¹
        return content.strip()

    def _extract_with_regex(self, content: str) -> Dict[str, List[str]]:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å†…å®¹

        Args:
            content: å†…å®¹å­—ç¬¦ä¸²

        Returns:
            å­¦ä¹ ç»“æœå­—å…¸
        """
        result = {
            "lessons": [],
            "key_points": [],
            "recommendations": []
        }

        # æå–lessonsï¼ˆç±»ä¼¼"lessons": [...])
        lessons_match = re.search(r'"lessons"\s*:\s*\[(.*?)\]', content, re.DOTALL)
        if lessons_match:
            lessons = re.findall(r'"([^"]*)"', lessons_match.group(1))
            result["lessons"] = lessons[:5] if len(lessons) > 5 else lessons

        # æå–key_points
        key_points_match = re.search(r'"key_points"\s*:\s*\[(.*?)\]', content, re.DOTALL)
        if key_points_match:
            key_points = re.findall(r'"([^"]*)"', key_points_match.group(1))
            result["key_points"] = key_points[:5] if len(key_points) > 5 else key_points

        # æå–recommendations
        recommendations_match = re.search(r'"recommendations"\s*:\s*\[(.*?)\]', content, re.DOTALL)
        if recommendations_match:
            recommendations = re.findall(r'"([^"]*)"', recommendations_match.group(1))
            result["recommendations"] = recommendations[:3] if len(recommendations) > 3 else recommendations

        # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not any(result.values()):
            logger.warning("æ­£åˆ™è¡¨è¾¾å¼æå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return self._get_default_result()

        return result

    def _get_default_result(self) -> Dict[str, List[str]]:
        """
        è·å–é»˜è®¤ç»“æœ

        Returns:
            é»˜è®¤å­¦ä¹ ç»“æœ
        """
        return {
            "lessons": [
                "åŸºç¡€æ¦‚å¿µå­¦ä¹ ",
                "æ ¸å¿ƒåŸç†ç†è§£",
                "å®é™…åº”ç”¨æŒæ¡"
            ],
            "key_points": [
                "å…³é”®çŸ¥è¯†ç‚¹1",
                "å…³é”®çŸ¥è¯†ç‚¹2",
                "å…³é”®çŸ¥è¯†ç‚¹3"
            ],
            "recommendations": [
                "å»ºè®®1ï¼šæ·±å…¥å­¦ä¹ ",
                "å»ºè®®2ï¼šå®è·µæ“ä½œ",
                "å»ºè®®3ï¼šæŒç»­å…³æ³¨"
            ]
        }

    def _get_default_content(self, key: str) -> List[str]:
        """
        è·å–é»˜è®¤å†…å®¹

        Args:
            key: å­—æ®µåç§°

        Returns:
            é»˜è®¤å†…å®¹åˆ—è¡¨
        """
        defaults = {
            "lessons": ["è¯¾ç¨‹1", "è¯¾ç¨‹2", "è¯¾ç¨‹3"],
            "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
            "recommendations": ["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]
        }
        return defaults.get(key, [])
